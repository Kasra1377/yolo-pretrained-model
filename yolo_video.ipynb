{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"yolo_video.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Pu_Y3CUtTe4RoEQTNOW2UgS6MPQHVYM7","authorship_tag":"ABX9TyOKMayg9Kcs11DdbO8vzWfD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"c0mZtJsOl9mq","executionInfo":{"status":"ok","timestamp":1629822955726,"user_tz":-270,"elapsed":818,"user":{"displayName":"Kasra Sadeghianpoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-M-IQfCdV1sDtftP0aqLtsS4eCJ8Pzr5Ka4Ee=s64","userId":"12889102283785354184"}}},"source":["# importing essential libraries\n","import numpy as np\n","import imutils\n","import time\n","import cv2\n","import os"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"uc1HjcVRmP1W","executionInfo":{"status":"ok","timestamp":1629822955730,"user_tz":-270,"elapsed":17,"user":{"displayName":"Kasra Sadeghianpoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-M-IQfCdV1sDtftP0aqLtsS4eCJ8Pzr5Ka4Ee=s64","userId":"12889102283785354184"}}},"source":["# defining the base config variables\n","THRESH = 0.3\n","CONFIDENCE = 0.5\n","INPUT_VID = \"videos/airplane.mp4\""],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XxC5DD9WmfRN","executionInfo":{"status":"ok","timestamp":1629822957058,"user_tz":-270,"elapsed":1343,"user":{"displayName":"Kasra Sadeghianpoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-M-IQfCdV1sDtftP0aqLtsS4eCJ8Pzr5Ka4Ee=s64","userId":"12889102283785354184"}},"outputId":"e38406f7-be75-4ba3-e166-4479d612c645"},"source":["# Changing the directory into notebooks paths\n","%cd /content/drive/MyDrive/My Projects/YOLO-pretrained-model"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/My Projects/YOLO-pretrained-model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7g9_PcuMn4jG","executionInfo":{"status":"ok","timestamp":1629822957060,"user_tz":-270,"elapsed":11,"user":{"displayName":"Kasra Sadeghianpoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-M-IQfCdV1sDtftP0aqLtsS4eCJ8Pzr5Ka4Ee=s64","userId":"12889102283785354184"}}},"source":["# loading the coco data and labels that yolo algorithm was trained on\n","labelsPath = os.path.sep.join([\"yolo-coco\" , \"coco.names\"])\n","# reading the labels by their path, remving the potential white spaces and split them by \\n\n","LABELS = open(labelsPath).read().strip().split(\"\\n\")\n","\n","# initializing some random colors for each label\n","np.random.seed(42)\n","COLORS = np.random.randint(0 , 255 , size = (len(LABELS) , 3) , dtype = \"uint8\")"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"DqsxQPfIoPa-","executionInfo":{"status":"ok","timestamp":1629822957061,"user_tz":-270,"elapsed":11,"user":{"displayName":"Kasra Sadeghianpoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-M-IQfCdV1sDtftP0aqLtsS4eCJ8Pzr5Ka4Ee=s64","userId":"12889102283785354184"}}},"source":["# passing the yolo weight and yolo config file locations into some varialbles\n","weightsPath = os.path.sep.join([\"yolo-coco\" , \"yolov3.weights\"])\n","configPath = os.path.sep.join([\"yolo-coco\" , \"yolov3.cfg\"])\n","\n","# loading the pretrained yolo model using opencv module\n","net = cv2.dnn.readNetFromDarknet(configPath , weightsPath)\n","\n","# determine only the *output* layer names that we need from yolo\n","ln = net.getLayerNames()\n","ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LuTh4NcPoj6W","executionInfo":{"status":"ok","timestamp":1629822957062,"user_tz":-270,"elapsed":11,"user":{"displayName":"Kasra Sadeghianpoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-M-IQfCdV1sDtftP0aqLtsS4eCJ8Pzr5Ka4Ee=s64","userId":"12889102283785354184"}},"outputId":"b4f2c3d9-1109-48c1-a40a-fd7c820f0782"},"source":["# loading the video file and initializing the frame dimensions\n","vs = cv2.VideoCapture(INPUT_VID)\n","writer = None\n","(W , H) = (None , None)\n","\n","# determine the total number of frames in input video file\n","try:\n","  prop = cv2.cv.CV_CAP_PROP_FRAME_COUNT if imutils.is_cv2() \\\n","      else cv2.CAP_PROP_FRAME_COUNT\n","  total = int(vs.get(prop))\n","  print(\"Total number of frames in the video is : \" , total)\n","\n","# if we can not get the total # of frames in the \n","# video, the code below will run\n","except:\n","  print(\"Could not determine # of frames in video\")\n","  total = -1"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Total number of frames in the video is :  187\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vvesXqikqpRP","executionInfo":{"status":"ok","timestamp":1629823370816,"user_tz":-270,"elapsed":413762,"user":{"displayName":"Kasra Sadeghianpoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-M-IQfCdV1sDtftP0aqLtsS4eCJ8Pzr5Ka4Ee=s64","userId":"12889102283785354184"}},"outputId":"804e5358-69c9-49de-c65e-2b6734a47cd3"},"source":["# looping over frames in the input video file\n","while True:\n","  # reading the next frame from the video file\n","  (grabbed , frame) = vs.read()\n","\n","  # if the frame was not grabbed then we end\n","  # the loop\n","  if not grabbed:\n","    break\n","  # if the frame dimensions are empty, grab them\n","  if W is None or H is None:\n","    (H , W) = frame.shape[:2]\n","\n","  # before feeding the frame to the yolo to get the bounding boxes and probabilities\n","  # first we have to preprocess our input frame\n","  blob = cv2.dnn.blobFromImage(frame , 1 / 255.0 , (416 , 416) , \n","                              swapRB = True , crop = False)\n","  # performing a forwardpass through the yolo\n","  net.setInput(blob)\n","  start = time.time()\n","  layerOutputs = net.forward(ln)\n","  end = time.time()\n","\n","  # initializing the list of detected bounding boxes, confidence\n","  # and class IDs\n","  boxes = []\n","  confidences = []\n","  classIDs = []\n","  # looping over each of the layer output\n","  for output in layerOutputs:\n","    # looping over each of the detections\n","    for detection in output:\n","      # extracting the clase ID and the confidence\n","      # for each of the current object detection\n","      scores = detection[5:]\n","      classID = np.argmax(scores)\n","      confidence = scores[classID]\n","\n","      if confidence > CONFIDENCE:\n","        # YOLO returns the (x,y) center coordinates of the ROI\n","        # so we have to scale it to the relative size of an image\n","        box = detection[0:4] * np.array([W , H , W , H])\n","        (centerX , centerY , width , height) = box.astype(\"int\")\n","\n","        # using the (x , y) center coordinates to calculate the top left\n","        # corner coordinate of the bounding box\n","        x = int(centerX - (width / 2))\n","        y = int(centerY - (height / 2))\n","        boxes.append([x , y , int(width) , int(height)])\n","        confidences.append(float(confidence))\n","        classIDs.append(classID)\n","  # using the cv2 nonMaxSuppression function to remove redundant\n","  # overlapping bounding boxes\n","  idxs = cv2.dnn.NMSBoxes(boxes , confidences , CONFIDENCE , THRESH)\n","\n","  # ensuring that at least one detection exists\n","  if len(idxs) > 0:\n","    for i in idxs.flatten():\n","      # extracting the bounding box coordinates\n","      (x , y) = (boxes[i][0] , boxes[i][1])\n","      (w , h) = (boxes[i][2], boxes[i][3])\n","\n","      # drawing the bounding box rectangle(s)\n","      color = [int(c) for c in COLORS[classIDs[i]]]\n","      cv2.rectangle(frame , (x ,y) , (x + w , y + h) , \n","                    color , 3)\n","      text = \"{} : {:.3f}\".format(LABELS[classIDs[i]] , confidences[i])\n","      cv2.putText(frame , text , (x , y - 5) , \n","                  cv2.FONT_HERSHEY_SIMPLEX , 0.5 , color , 2)\n","    \n","  # check if the video writer in None\n","  if writer is None:\n","    # initializing our video writer\n","    fourcc = cv2.VideoWriter_fourcc(*\"MP4V\")\n","    writer = cv2.VideoWriter(\"airplane_final.mp4\" , fourcc , 20.0 , \n","                  (frame.shape[1] , frame.shape[0]) , True)\n","    \n","    # some information on processing single frame\n","    if total > 0:\n","      elap = (end - start)\n","      print(\"A single frame took {:.3f} seconds.\".format(elap))\n","      print(\"The whole video took {:.3f} seconds.\".format(elap * total))\n","  \n","  # writing the output frame to disk\n","  writer.write(frame)\n","\n","writer.release()\n","vs.release()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["A single frame took 2.496 seconds.\n","The whole video took 466.792 seconds.\n"],"name":"stdout"}]}]}